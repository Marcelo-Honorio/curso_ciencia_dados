---
title: "Aprendizado Supervisionado"
author: "Marcelo Honorio"
format: 
  revealjs:
    output-file: supervisionado.html
    theme: custom.scss
    transition: fade
    background-transition: fade
    highlight-style: ayu-mirage
    slide-number: c/t
    show-slide-number: all
editor: 
  markdown: 
    wrap: 72
---

## Supervisionado e N√£o Supervisionado

```{r echo=FALSE, out.width="40%"}
#| fig-align: "center"
knitr::include_graphics("imagens/sup-uns-learning2.jpg")
```

## Supervisionado e N√£o Supervisionado

```{r echo=FALSE, out.width="40%"}
#| fig-align: "center"
knitr::include_graphics("imagens/sup-uns-learning.jpg")
```

## Modelos lineares generalizados

<br>

```{r echo=FALSE, out.width="60%"}
#| fig-align: "center"
knitr::include_graphics("imagens/modelos_generalizados.jpg")
```


```{r}
#| echo: false
#| message: false

# load packages
library(pROC)
library(plotly)
library(tidyverse)       # for data wrangling
library(tidymodels)      # for modeling
library(fivethirtyeight) # for the fandango dataset
```

```{r}
#| echo: false
load(file = "tempodist.RData")
```

# Modelo de Regress√£o

## Dados

<br>

::: {.columns}
::: {.column width="40%"}

```{r, echo=FALSE}
estudante <- c('Gabriela', 'Dalila', 'Gustavo', 'Let√≠cia', 'Luiz', 'Leonor', 'Ana', 'Ant√¥nio', 'J√∫lia', 'Mariana')

tempodist_q <- cbind(estudante, tempodist)

knitr::kable(tempodist_q, col.names = gsub("[.]", " ", names(tempodist_q)), align = "lccrr") |> 
  kableExtra::kable_styling(bootstrap_options = c('striped', 'condensed', 'houver'), full_width = F, row_label_position = "c", font_size = 20)
```
:::
::: {.column width="60%"}

**Visualiza√ß√£o**
```{r}
ggplot(tempodist, 
       aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 3) +
  theme_classic() +
  theme(axis.title = element_text(size = 18)) +
  labs(
    x = "Dist√¢ncia" , 
    y = "Tempo"
    )
```
:::
:::

## Forma linear

... Para descrever a rela√ß√£o entre a dist√¢ncia e tempo
```{r}
#| out.width: "70%"
p <- ggplot(data = tempodist, 
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 2) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  theme_classic() +
  theme(axis.title = element_text(size = 18)) +
  labs(
    x = "dist√¢ncia" , 
    y = "tempo"
    )

p
```

## Modelo de regress√£o

::: columns
::: {.column width="30%"}
-   **Resultado, Y**: vari√°vel que descreve os resultado de interesse
-   **Preditor, X**: vari√°vel usada para ajudar a entender a variabilidade no resultado
:::

::: {.column width="70%"}

$$Y_i = \beta_0 + \beta_1 X_i + e_i$$
```{r}
#| out.width: "100%"
p
```
:::
:::

## Modelo de regress√£o

<br>

Um modelo de regress√£o √© uma fun√ß√£o que descreve a rela√ß√£o entre o resultado, $Y$, e o preditor, $X$.

$$\displaystyle \begin{aligned} Y &= \color{black}{\textbf{Modelo}} + \text{Error} \\[8pt]
&= \color{black}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{black}{\boldsymbol{\mu_{Y|X}}} + \epsilon \end{aligned}$$

##  Modelo de regress√£o

<br>

::: columns
::: {.column width="30%"}
$$\displaystyle
\begin{aligned} Y &= \color{purple}{\textbf{Modelo}} + \text{Error} \\[8pt]
&= \color{purple}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{purple}{\boldsymbol{\mu_{Y|X}}} + \epsilon 
\end{aligned}
$$
:::

::: {.column width="70%"}
```{r}
m <- lm(tempo ~ distancia, data = tempodist)

ggplot(data = tempodist, 
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 2) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(x = "X", y = "Y") +
  theme_classic() +
  theme(
    axis.title = element_text(size = 18),
    axis.text = element_blank(),
    axis.ticks.x = element_blank(), 
    axis.ticks.y = element_blank()
    )
```
:::
:::

## Modelo de regress√£o + residuos

<br>

::: columns
::: {.column width="30%"}
$$\begin{aligned} Y &= \color{purple}{\textbf{Modelo}} + \color{blue}{\textbf{Error}} \\[8pt]
&= \color{purple}{\mathbf{f(X)}} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
&= \color{purple}{\boldsymbol{\mu_{Y|X}}} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
 \end{aligned}$$
:::

::: {.column width="70%"}
```{r}
#| echo: false
ggplot(data = tempodist,
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  geom_segment(aes(x = distancia, xend = distancia, 
                   y = tempo, yend = predict(m)), 
               color = "blue") +
  labs(x = "X", y = "Y") +
  theme_classic() +
  theme(
    axis.title = element_text(size = 18),
    axis.text = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank()
  )
```
:::
:::

# Regress√£o linear simples

## Regress√£o linear simples

Para modelar a rela√ß√£o entre um resultado quantitativo ($Y$) e um √∫nico preditor quantitativo ($X$): 
$$\Large{Y = \beta_0 + \beta_1 X + e}$$

::: incremental
-   $\beta_1$: Inclina√ß√£o da rela√ß√£o entre $X$ e $Y$
-   $\beta_0$: Intercepto da rela√ß√£o entre $X$ e $Y$
-   $X$: Vari√°vel explicativa
-   $e$ : Erro (residual)
:::

## Regress√£o linear simples

**Objetivo**: desenvolver uma equa√ß√£o linear que apresente a rela√ß√£o entre uma vari√°vel dependente e uma explicativa

$$\Large{\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X}$$

-   $\hat{\beta}_1$: Inclina√ß√£o estimada da rela√ß√£o entre $X$ e $Y$
-   $\hat{\beta}_0$: Intercepto estimado da rela√ß√£o entre $X$ e $Y$
-   Sem termo de erro!

## Residual

O termo de erro dever√° capturar o efeito das demais vari√°veis n√£o incluidas no modelo.

```{r}
#| warning: false
#| message: false
#| fig-align: center
ggplot(data = tempodist, mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  geom_segment(aes(x = distancia, xend = distancia, y = tempo, yend = predict(m)), color = "steel blue") +
  labs(x = "Dist√¢ncia", y = "Tempo") +
  theme_classic() +
  theme(axis.title = element_text(size = 18))+
  theme(legend.position = "none")
```

$$\text{residual} = \text{observado} - \text{previsto} = y - \hat{y}$$

## Condi√ß√µes relacionadas aos res√≠duos

<br>

**1. A somat√≥ria dos residuos deve ser zero:** $\sum_{i=1}^n u_i = 0$

```{r}
ggplot(data = tempodist, 
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 2) + 
  geom_abline(intercept = 5.878, slope = 1.419, color = "purple", size = 2) +
  geom_abline(intercept = 4.8, slope = 1.6, color = "red") +
  geom_abline(intercept = 3, slope = 1.8, color = "red") +
  geom_abline(intercept = 6.9, slope = 1.2, color = "red") +
  theme_classic() +
  theme(axis.title = element_text(size = 18))+
  labs(x = "Dist√¢ncia", y = "Tempo")
```

## Condi√ß√µes relacionadas aos res√≠duos

<br>

**2. A somat√≥ria dos res√≠duos ao quadrado √© a m√≠nima poss√≠vel:** $\sum_{i=1}^n u_i^n = \text{m√≠n}$

```{r}
ggplot(data = tempodist, 
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.7, size = 2) + 
  geom_abline(intercept = 5.878, slope = 1.419, color = "purple", size = 2) +
  geom_abline(intercept = 4.8, slope = 1.6, color = "red") +
  geom_abline(intercept = 3, slope = 1.8, color = "red") +
  geom_abline(intercept = 6.9, slope = 1.2, color = "red") +
  theme_classic() +
  theme(axis.title = element_text(size = 18))+
  labs(x = "Dist√¢ncia", y = "Tempo")
```


## Estimando valores para $\hat{\beta}_1$ e $\hat{\beta}_0$

```{r}
ggplot(data = tempodist, 
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.5) + 
  geom_abline(intercept = 5.878, slope = 1.419, color = "purple", size = 2) +
  geom_abline(intercept = 4.8, slope = 1.6, color = "red") +
  geom_abline(intercept = 3, slope = 1.8, color = "red") +
  geom_abline(intercept = 6.9, slope = 1.2, color = "red") +
  theme_classic() +
  theme(axis.title = element_text(size = 18))+
  labs(x = "Dist√¢ncia", y = "Tempo")
```

## An√°lise inicial 

<br>

$$\widehat{\text{tempo}} = 5.878 + 1.419 \times \text{distancia}$$
```{r}
#| fig-align: center
summary(m)
```

## An√°lise inicial
```{r, echo=F}
constante <- c(30, 35, 30, 35, 30, 35, 35, 30, 35, 30)
x_constate <- c(1, 2, 3, 4, 5, 5, 6, 7, 8, 9)
aleatorio <- sample(20:60, 10, replace=TRUE)

tempodist_r <- cbind(tempodist, constante, aleatorio)

m <- lm(tempo ~ distancia, data = tempodist)
m1 <- lm(tempo ~ aleatorio, data = tempodist_r)
m2 <- lm(tempo ~ constante, data = tempodist_r)
```

**$R^2$** coeficiente de ajuste do modelo, indica o percentual de vari√¢ncia da vari√°vel $Y$ que √© devido ao comportamento de varia√ß√£o conjunta da(s) vari√°vel(is) explicativa(s).

```{r, echo=F}
#| fig-align: center
ggplot(data = tempodist_r,
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = m$coefficients[1], slope = m$coefficients[2], color = "purple", size = 1) +
  labs(title = paste("R¬≤: ", round(summary(m)$r.squared, 4)),
       x = "X", y = "Y") +
  theme(
    axis.text = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  scale_x_continuous(limits = c(0, 35)) +
  scale_y_continuous(limits = c(0, 60))
```


## $R^2$

::: columns

::: column
```{r, echo=F}
ggplot(data = tempodist_r,
       mapping = aes(x = distancia, y = tempo)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = m$coefficients[1], slope = m$coefficients[2], color = "purple", size = 1) +
  labs(title = paste("R¬≤: ", round(summary(m)$r.squared, 4)),
       x = "X", y = "Y") +
  theme(
    plot.title = element_text(size = 25),
    axis.title = element_text(size = 18),
    axis.text = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  scale_x_continuous(limits = c(0, 35)) +
  scale_y_continuous(limits = c(0, 60))
```

:::
::: column
```{r, echo=F}
ggplot(data = tempodist_r,
       mapping = aes(x = aleatorio, y = tempo)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = m1$coefficients[1], slope = m1$coefficients[2], color = "purple", size = 1) +
  labs(title = paste("R¬≤: ", round(summary(m1)$r.squared, 4)),
       x = "X", y = "Y") +
  theme(
    plot.title = element_text(size = 25),
    axis.title = element_text(size = 18),
    axis.text = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank()
  )+
  scale_x_continuous(limits = c(0, 60)) +
  scale_y_continuous(limits = c(0, 60))
```
:::
:::

```{r, echo=F}
#| out.width: "50%"
#| fig-align: center
ggplot(data = tempodist_r,
       mapping = aes(x = x_constate, y = constante)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(title = paste("R¬≤: ", round(summary(m2)$r.squared)),
       x = "X", y = "Y") +
  theme(
    plot.title = element_text(size = 25),
    axis.title = element_text(size = 18),
    axis.text = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  scale_x_continuous(limits = c(0, 12)) +
  scale_y_continuous(limits = c(0, 60))
```

## Teste F

**Teste F**: Analisa se pelo menos um dos $\beta'$s √© significativo para a explica√ß√£o de $Y$

  **Hip√≥teses**: 
  
  -   $H_0 :\beta_1 = \beta_2 = \beta_3 = ...\beta_k = 0$ 
  
  -   $H_1 : pelo\ menos\ um\ \beta \neq 0$


> Espera-se rejeitar a hip√≥tese nula, ou seja, que pelo menos um dos $\beta'$s seja estatisticamente diferente de zero para explicar o comportamento de Y - p-valor abaixo de n√≠vel cr√≠tico (0,05, usualmente)

## Teste $t$

Analisa individualmente cada um dos par√¢metros, identificando se os mesmo s√£o estatisticamente diferentes de zero.

  **Hip√≥teses**:
  
  -   $H_0: \beta = 0$ 
  
  -   $H_1: \beta \neq 0$

> Espera-se o mesmo fato, em termos de signific√¢ncia estat√≠stica, do que o discutido para o teste F.


## Predi√ß√£o

<br>

Suponha que um estudante more √† 20 km de dist√¢ncia. De acordo com esse modelo, qual √© o tempo previsto para chegar?

$$
\begin{aligned}
\widehat{\text{tempo}} &= 5.878 + 1.419 \times \text{distancia} \\
&= 5.878 + 1.419 \times 20 \\
&= 34.258
\end{aligned}
$$

√â **importante** realizar infer√™ncias sobre o comportamento de uma vari√°vel $Y$ dentreo dos limites de varia√ß√£o de $X$.


# Regress√£o M√∫ltipla

## Regress√£o M√∫ltipla

<br>

Qual a diferen√ßa entre um modelo de regress√£o simples para um modelo de regress√£o m√∫ltipla?

. . .

A forma funcional passa a ser a seguinte:
$$\displaystyle{Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i}... + \beta_k X_{ki} + \epsilon}$$

A regress√£o linear m√∫ltipla apresenta a mesma l√≥gica apresentada para a regress√£o linear simples.

## Regress√£o M√∫ltipla

A inlcus√£o de mais vari√°veis depender√° da teoria subjacente e de estudos anteriores, bem como da experi√™ncia e do bom senso do pesquisador.

```{r}
estudante <- c('Gabriela', 'Dalila', 'Gustavo', 'Let√≠cia', 'Luiz', 'Leonor', 'Ana', 'Ant√¥nio', 'J√∫lia', 'Mariana')
semafaro <- c(0, 1, 0, 1, 2, 1, 0, 3, 1, 1)

tempodist_s <- cbind(estudante, tempodist, semafaro)

knitr::kable(tempodist_s, col.names = gsub("[.]", " ", names(tempodist_s)), align = "lccrr") |> 
  kableExtra::kable_styling(bootstrap_options = c('striped', 'condensed', 'houver'), full_width = F, row_label_position = "c", font_size = 18)
```

$$\widehat{\text{tempo}_i} = \alpha + \beta_1.dist_i + \beta_2.sem_i$$

## An√°lise Regress√£o M√∫ltipla

$$\widehat{\text{tempo}} = 8.1512 + 0.7972 \times \text{distancia} + 8.2963\times \text{semafaro}$$

```{r, echo=FALSE}
m1 <- lm(tempo ~ distancia + semafaro, data = tempodist_s)

summary(m1)
```

## An√°lise Regress√£o M√∫ltipla

<br>

Quando houver o intuito de se compararem os resultados das estima√ß√µes de dois modelos com quantidades distintas de par√¢metros e/ou obtidos a partir de amostras com tamanhos diferentes, faz-se necess√°rio o uso do **R¬≤ ajustado**.

$$\displaystyle R_{ajust}^2 = 1 - \frac{n - 1}{n - k}(1 - R^2)$$

-   $n$ tamanho da amostra
-   $k$ √© o n√∫mero de par√¢metros do modelo

## Comparando Regress√µes

:::{.columns}
:::{.column}

**Regress√£o Simples**
```{r, echo=FALSE}
summary(m)
```
:::
:::{.column}

**Regress√£o M√∫ltipla**
```{r, echo=FALSE}
summary(m1)
```
:::
:::

## Regress√£o M√∫ltipla

<br>

```{r}
periodo <- c('manha', 'manha', 'manha', 'tarde', 'tarde', 'manha', 'manha', 'tarde', 'manha', 'manha')

perfil <- c('calmo', 'moderado', 'moderado', 'agressivo', 'agressivo', 'moderado', 'calmo', 'calmo', 'moderado', 'moderado')

tempodist_s <- cbind(tempodist_s, periodo, perfil)

knitr::kable(tempodist_s, col.names = gsub("[.]", " ", names(tempodist_s)), align = "lccrr") |> 
  kableExtra::kable_styling(bootstrap_options = c('striped', 'condensed', 'houver'), full_width = F, row_label_position = "c", font_size = 20)
```

## Vari√°veis qualitativas

S√£o vari√°veis categ√≥ricas que representam um atributo por meio de combina√ß√£o **bin√°ria** (0 para a aus√™ncia ou 1 para presen√ßa).

```{r, echo=FALSE}
knitr::kable(tempodist_s, col.names = gsub("[.]", " ", names(tempodist_s)), align = "lccrr") |> 
  kableExtra::kable_styling(bootstrap_options = c('striped', 'condensed', 'houver'), full_width = F, row_label_position = "c", font_size = 20)
             
```

## Vari√°veis qualitativas

Para uma vari√°vel categ√≥rica com mais de duas categorias?

. . .

Neste caso, devemos incluir $n - 1$ *dummies*, em que $n$ √© a quantidade de categorias existentes na vari√°vel original.

```{r, echo=FALSE}
library(fastDummies)
df_b <- dummy_cols(tempodist_s, select_columns = c('periodo', 'perfil'), remove_first_dummy = TRUE)

knitr::kable(df_b, col.names = gsub("[.]", " ", names(df_b)), align = "lccrr") |> 
  kableExtra::kable_styling(bootstrap_options = c('striped', 'condensed', 'houver'), full_width = F, row_label_position = "c", font_size = 20)
```


## Regress√£o M√∫ltipla

```{r, echo=FALSE}
#| panel: center
#| layout-align: center
m2 <- lm(tempo ~ distancia + semafaro + periodo + perfil, data = tempodist_s)

summary(m2)
```

## Regress√£o Stepwise

<br>

O m√©todo stepwise √© usado para selecionar quais vari√°veis mais influenciam o conjunto de sa√≠da podendo, assim, diminuir o n√∫mero de vari√°veis a compor a equa√ß√£o de regress√£o.

# Modelos n√£o lineares

## Modelos n√£o lineares

::: columns
::: column
```{r echo=FALSE, out.width="80%"}
#| fig-align: "center"
knitr::include_graphics("imagens/nao_linear1.png")
```
:::
::: column
```{r echo=FALSE, out.width="80%"}
#| fig-align: "center"
knitr::include_graphics("imagens/nao_linear2.png")
```
:::
:::

```{r echo=FALSE, out.width="40%"}
#| fig-align: "center"
knitr::include_graphics("imagens/nao_linear2.png")
```

Resultados da aplica√ß√£o de quatro diferentes formas funcionais em regress√£o

## Pressupostos do modelo de regress√£o

<br>

```{r echo=FALSE, out.width="40%"}
#| fig-align: "center"
knitr::include_graphics("imagens/pressupostos.jpg")
```

## Normalidade dos res√≠duos

<br>

A n√£o ader√™ncia √† normalidade dos termos de erro pode indicar que o medelo foi especificado incorretamente quanto √† forma funcional e que houve a omiss√£o de vari√°veis explicativas. 

```{r echo=FALSE, out.width="60%"}
knitr::include_graphics("imagens/residual_normalidade.jpg")
```


## Normalizar por Box-Cox

Para que seja corrigido este problema, pode-se alterar a formula√ß√£o matem√°tica.$\lambda$ √© o par√¢metro que maximiza a ader√™ncia √† normalidade da districui√ß√£o da nova vari√°vel. 
$$\displaystyle \frac{Y_i^\lambda - 1}{\lambda} = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i}... + \beta_k X_{ki} + \epsilon$$
```{r echo=FALSE, out.width="50%"}
#| fig-align: "center"
knitr::include_graphics("imagens/box-cox.jpg")
```

# Regress√£o Log√≠stica Bin√°ria

## Regress√£o Log√≠stica Bin√°ria

<br>

T√©cnica supervisionada de machine learning utilizada para explicar ou predizer a probabilidade de ocorr√™ncia de determinado evento em fun√ß√£o de uma ou mais vari√°veis explicativas.

**Vari√°vel dependente**: bin√°ria

>  Resultados interpretados em termos de probabilidades.

**Vari√°veis do vetor X**: m√©tricas ou n√£o m√©tricas

## Objetivos da t√©cnica

<br>

**Atribui√ß√£o de probabilidades**: 

estimar a probabilidade de ocorr√™ncia de determinando evento ou de que um indiv√≠duo venha a se enquadrar nessa ou naquela categoria.

<br>

**Classifica√ß√£o em categorias**: 

classificar indiv√≠duos ou observa√ß√µes em categorias espec√≠ficas.

## Dados

:::{.columns}
:::{.column}

Agora a vari√°vel alvo √© categ√≥rica.

1: atrasado

0: n√£o atrasado

:::
:::{.column}
```{r, echo=FALSE}
atrasado <- readr::read_rds("atrasado.rds")

atrasado
```
:::
:::

## Visualiza√ß√£o dos dados

```{r, echo=FALSE}
ggplot(atrasado, aes(x = dist, y = atrasado)) +
  geom_point() + 
  labs(y = "Chegou Atrasado") +
  theme_classic()

```

## Testando modelo linear

**Resultado**: $Y$ = 1: sim, 0: n√£o 

```{r, echo=FALSE}
ggplot(atrasado, aes(x = dist, y = atrasado)) +
  geom_point() + 
  labs(y = "Chegou Atrasado") +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  theme_classic()

```

## Vamos usar propor√ß√µes

**Resultado**: Probabilidade de chegar atrasado

```{r, echo=FALSE}
atrasado_dist <- atrasado  |> 
  mutate(dist = round(dist)) |> 
  group_by(dist)  |> 
  summarise(prop = mean(atrasado))

ggplot(atrasado_dist, aes(x = dist, y = prop)) +
  geom_point() + 
  labs(y = "P(Chegou Atrasado)") +
  geom_hline(yintercept = c(0,1), lty = 2) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  theme_classic()

```

## Vamos usar propor√ß√µes

**Resultado**: Probabilidade de chegar atrasado
```{r, echo=FALSE}
ggplot(atrasado_dist, aes(x = dist, y = prop)) +
  geom_point() + 
  geom_hline(yintercept = c(0,1), lty = 2) +
  labs(y = "P(Chegou Atrasado)") +
  geom_smooth(method = "lm", color = "purple", se = FALSE, fullrange = TRUE) +
  theme_classic() +
  xlim(1, 55) +
  ylim(-1, 2)
```

üõë *Este modelo produz previs√µes fora do 0 e 1.*

## Testando outro modelo

```{r}
#| label: logistic-model-plot
#| echo: false

ggplot(atrasado_dist, aes(x = dist, y = prop)) +
  geom_point() + 
  geom_hline(yintercept = c(0,1), lty = 2) + 
  stat_smooth(method ="glm", method.args = list(family = "binomial"), 
              fullrange = TRUE, se = FALSE) +
  labs(y = "P(Chegou Atrasado)") +
  theme_classic() +
  xlim(1, 55) +
  ylim(-1, 2)
```

‚úÖ **O Modelo de regress√£o log√≠stica s√≥ produz previs√µes entre 0 e 1**

## Tipos de modelos

| M√©todo                          | Resultado    | Fun√ß√£o                                                     |
|---------------------------------|--------------|-----------------------------------------------------------|
| Regress√£o linear                | Quantitativo | $Y = \beta_0 + \beta_1~ X$                                |
| Regress√£o linear (transform Y) | Quantitativo | $\log(Y) = \beta_0 + \beta_1~ X$                          |
| Regress√£o Log√≠stica             | Bin√°rio       | $\log\big(\frac{\pi}{1-\pi}\big) = \beta_0 + \beta_1 ~ X$ |

# Chance (Odds) e probabilidade

## Probabilidade

<br>

Seja $Y$ a resposta a um est√≠mulo (sim ou n√£o) - pode ser a prefer√™ncia por um produto, adimpl√™ncia, aprova√ß√£o em um curso, etc.

-   **$p$** : probabilidade da resposta "sim".

-   **$1 - p$** : probabilidade da resposta "n√£o"

## Chance (ODDS)

<br>

Chance (odds) de ocorr√™ncia de um evento:

$$\displaystyle chance = \frac {p}{1 - p}$$

-   **$p$** : Evento

-   **$1 - p$** : N√£o Evento

**Exemplo**: 

  se $p = 0,75$, chance = 3 (3 para 1)

## Logito

logaritmo natural da chance de ocorr√™ncia de uma resposta do tipo ‚Äúsim‚Äù. $Z = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i}... + \beta_k X_{ki} + \epsilon$

$$\displaystyle logito = Z = ln \left(\frac {p}{1 - p} \right)$$

$$\displaystyle e^{logito} = e^Z = \frac {p}{1 - p} = odds$$

$$\displaystyle p = \frac {e^Z}{1 + e^Z} = \frac {1}{1 + e^{-Z}}$$

## Regress√£o log√≠stica

<br>

A curva log√≠stica, ou sigm√≥ide, descreve a rela√ß√£o entre a probabilidade associada √† ocorr√™ncia de determinando evento e um conjunto de vari√°veis preditoras.

$$\displaystyle p_i = \frac {1}{1 + e^{-Z}} = \frac {1}{1 + e^{-(\beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i}... + \beta_k X_{ki} + \epsilon)}}$$

## Fun√ß√£o log√≠stica

<br>

$$\displaystyle p_i = \frac {1}{1 + e^{-Z}} = \frac {1}{1 + e^{-(\beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i}... + \beta_k X_{ki} + \epsilon)}}$$

-   Estima√ß√£o dos par√¢metros: processo iterativo para maximizar o acerto da probabilidade
de ocorr√™ncia de um evento √† sua real ocorr√™ncia (M√©todo de M√°xima Verossimilhan√ßa).


## Fun√ß√£o log√≠stica

<br>

$$\displaystyle p_i = \frac {1}{1 + e^{-Z}} = \frac {1}{1 + e^{-(\beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i}... + \beta_k X_{ki} + \epsilon)}}$$

-   Os resultados atribu√≠veis √† vari√°vel dependente estar√£o entre 0 e 1.

-   An√°lise do ajuste do modelo: testes de signific√¢ncia dos par√¢metros e tabela de
classifica√ß√£o (matriz de confus√£o).

## Cutoff, sensitividade e especificidade

<br>

O **cutoff** √© definido para que sejam classificadas as observa√ß√µes em fun√ß√£o das suas probabilidades calculadas.

-   Se $p_i$ > *cutoff*: $i$ dever√° classificado como evento
-   Se $p_i$ < *cutoff*: $i$ dever√° classificado como n√£o evento

## Cutoff, sensitividade e especificidade {.smaller}

|                              | aluno atrasou                    | aluno n√£o atrasou                  |
|------------------------------|----------------------------------|------------------------------------|
| Classificado com Evento      | Verdadeiro positivo               | Falso positivo                    |
| Classificado como N√£o Evento | Falso negativo                    | Verdadeiro negativo               |

-   **sensitividade** : percentual de acerto considerando-se apenas as observa√ß√µes que de fato s√£o evento.
$$Sensitividade = \frac {\text{verdadeiro positivo}}{\text{total de evento}}$$
-   **especificidade** : percentual de acerto considerando-se apenas as observa√ß√µes que n√£o s√£o evento.
$$Especificidade = \frac {\text{falso negativo}}{\text{total de n√£o evento}}$$

## Curva ROC

Mostra o comportamento propriamente dito do *trade off* entre sensitividade e especificidade.

```{r, echo=FALSE}
atrasado <- readRDS("atrasado.rds")

# Estima√ß√£o de modelo Log√≠stico Bin√°rio
modelo_atrasos <- glm(formula = atrasado ~ dist + sem, 
                      data = atrasado, 
                      family = "binomial")


ROC <- roc(response = atrasado$atrasado, 
           predictor = modelo_atrasos$fitted.values)

ggplotly(
  ggroc(ROC, color = "darkorchid", size = 1) +
    geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), 
                 color="orange", 
                 linewidth = 0.2)+
    labs(x = "1 - Especificidade",
         y = "Sensitividade",
         title = paste("√Årea abaixo da curva:", 
                       round(ROC$auc, 3))) +
    theme_bw()
    )

```

Modelos com maior √°rea abaixo da curva ROC apresenta maior efici√™ncia global de previs√£o.

# Outros modelos

## √Årvore de decis√£o

A nomenclatura √°rvore deriva da metodologia proposta. Sua estrutura√ß√£o envolve o n√≥ raiz, os n√≥s de decis√£o e os n√≥s folha.

```{r echo=FALSE, out.width="80%"}
#| fig-align: "center"
knitr::include_graphics("imagens/arvore_decisao.png")
```

## Ideia central - mudar

Vamos supor que queremos descobrir o nome de um personagem escolhido aleatoriamente. 

```{r echo=FALSE, out.width="80%"}
#| fig-align: "center"
knitr::include_graphics("imagens/turma_monica.jpg")
```

Qual deveria ser a primeira pergunta?

. . .

- O personagem √© do sexo feminino?
- O personagem possui um coelho de pel√∫cia?

## Iniciando pela pergunta 2:

```{r echo=FALSE, out.width="100%"}
#| fig-align: "center"
knitr::include_graphics("imagens/pergunta1.png")
```

## Iniciando pela pergunta 1:

```{r echo=FALSE, out.width="100%"}
#| fig-align: "center"
knitr::include_graphics("imagens/pergunta2.png")
```

## Objetivo central

Descobrir quais vari√°veis possuem a maior carga de informa√ß√£o para que as perguntas "corretas" possam ser feitas.

<br>

Como medir a melhor parti√ß√£o em cada etapa do processo?

-   Entropia de **Shannon**

-   Coeficiente de **Gini**

## Ganho de informa√ß√£o

<br>

Um crit√©rio muito utilizado √© o √≠ndice de Gini:

$$I(Y, D) = 1-\sum_{i=i}^m p_i^2$$

O Coeficiente de Gini ser√° 0 quando todas as $i$ observa√ß√µes pertencerem a mesma classe $ùëö$, e $1 ‚àí \frac {1}{m}$ quando todas as $ùëö$ classes possu√≠rem a mesma probabilidade de ocorr√™ncia.



